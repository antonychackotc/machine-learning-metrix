{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPX1Nebr6UFl4l09k3gLZ/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antonychackotc/machine-learning-metrix/blob/main/activity_6(jan_13)machine_learning_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLVBTVTDDgo_",
        "outputId": "e5545000-90ad-4c4c-aa98-76cf8384e5c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m489.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement localtunnel (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for localtunnel\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit\n",
        "!pip install -q pyngrok\n",
        "!pip install -q localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app1.py"
      ],
      "metadata": {
        "id": "dm3e3krXDz7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e4ecf2-4dba-49ef-bd0f-8f06f42bf841"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app1.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, r2_score,\n",
        "    mean_absolute_error, mean_squared_error\n",
        ")\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.svm import SVR, SVC\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Function to evaluate regression models with detailed metrics\n",
        "def evaluate_regression(model, X_test, y_test, X_train):\n",
        "    y_pred = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    adj_r2 = 1 - (1 - r2) * (len(y_test) - 1) / (X_train.shape[0] - X_train.shape[1] - 1)\n",
        "    return {\n",
        "        \"MAE\": mae,\n",
        "        \"MSE\": mse,\n",
        "        \"RMSE\": rmse,\n",
        "        \"R2\": r2,\n",
        "        \"Adjusted R2\": adj_r2\n",
        "    }\n",
        "\n",
        "# Function to evaluate classification models with detailed metrics\n",
        "def evaluate_classification(model, X_test, y_test, balance):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    metrics = {\"Accuracy\": accuracy}\n",
        "\n",
        "    if not balance:  # Unbalanced data\n",
        "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        metrics.update({\"Precision\": precision, \"Recall\": recall, \"F1 Score\": f1})\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Function to apply a single model\n",
        "def apply_single_model(X_train, X_test, y_train, y_test, model_name, task_type, balance):\n",
        "    model_map = {\n",
        "        \"Linear Regression\": LinearRegression(),\n",
        "        \"Ridge Regression\": Ridge(),\n",
        "        \"Lasso Regression\": Lasso(),\n",
        "        \"ElasticNet Regression\": ElasticNet(),\n",
        "        \"SVM Regression\": SVR(),\n",
        "        \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
        "        \"Random Forest Regressor\": RandomForestRegressor(),\n",
        "        \"Boosting Regressor\": GradientBoostingRegressor(),\n",
        "        \"KNN Regressor\": KNeighborsRegressor(),\n",
        "        \"Logistic Regression\": LogisticRegression(),\n",
        "        \"SVM Classifier\": SVC(),\n",
        "        \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
        "        \"Random Forest Classifier\": RandomForestClassifier(),\n",
        "        \"Boosting Classifier\": GradientBoostingClassifier(),\n",
        "        \"KNN Classifier\": KNeighborsClassifier(),\n",
        "        \"Naive Bayes Classifier\": GaussianNB(),\n",
        "    }\n",
        "\n",
        "    if model_name == \"Polynomial Regression\":\n",
        "        poly = PolynomialFeatures(degree=2)\n",
        "        X_train_poly = poly.fit_transform(X_train)\n",
        "        X_test_poly = poly.transform(X_test)\n",
        "        lin_reg = LinearRegression()\n",
        "        lin_reg.fit(X_train_poly, y_train)\n",
        "        metrics = evaluate_regression(lin_reg, X_test_poly, y_test, X_train_poly)\n",
        "        trained_model = lin_reg\n",
        "    else:\n",
        "        model = model_map[model_name]\n",
        "        model.fit(X_train, y_train)\n",
        "        if task_type == 'regression':\n",
        "            metrics = evaluate_regression(model, X_test, y_test, X_train)\n",
        "        else:\n",
        "            metrics = evaluate_classification(model, X_test, y_test, balance)\n",
        "        trained_model = model\n",
        "\n",
        "    return trained_model, metrics\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Automated Model Selection with Future Prediction\")\n",
        "\n",
        "# Tabs for better navigation\n",
        "tabs = st.tabs([\"Data Analysis\", \"Model Evaluation\", \"Future Prediction\"])\n",
        "\n",
        "with tabs[0]:  # Data Analysis Tab\n",
        "    st.header(\"Data Analysis\")\n",
        "    uploaded_file = st.file_uploader(\"Upload your dataset (CSV format):\", type=[\"csv\"])\n",
        "    if uploaded_file is not None:\n",
        "        data = pd.read_csv(uploaded_file)\n",
        "        st.write(\"Dataset Preview:\", data.head())\n",
        "\n",
        "        y_col = st.selectbox(\"Select the target column:\", data.columns)\n",
        "        if y_col:\n",
        "            y = data[y_col]\n",
        "            unique_values = y.nunique()\n",
        "\n",
        "            # Determine if the data is continuous or discrete\n",
        "            if y.dtype in [np.int64, np.float64]:\n",
        "                if unique_values > 20:\n",
        "                    inferred_task_type = 'regression'\n",
        "                    data_type = \"Continuous\"\n",
        "                else:\n",
        "                    inferred_task_type = 'classification'\n",
        "                    data_type = \"Discrete\"\n",
        "            else:\n",
        "                inferred_task_type = 'classification'\n",
        "                data_type = \"Discrete\"\n",
        "\n",
        "            balance = inferred_task_type == 'classification' and (y.value_counts(normalize=True).max() <= 0.7)\n",
        "\n",
        "            st.write(f\"**Target Column Data Type:** {data_type}\")\n",
        "            st.write(f\"**Inferred Task Type:** {inferred_task_type}\")\n",
        "            st.write(f\"**Data Balance:** {'Balanced' if balance else 'Unbalanced'}\")\n",
        "            if inferred_task_type == 'regression':\n",
        "                st.write(\"**Suggested Model:** Linear Regression or Random Forest Regressor\")\n",
        "            else:\n",
        "                st.write(\"**Suggested Model:** Random Forest Classifier or Logistic Regression\")\n",
        "\n",
        "\n",
        "with tabs[1]:  # Model Evaluation Tab\n",
        "    st.header(\"Model Evaluation\")\n",
        "    if uploaded_file is not None:\n",
        "        X_cols = st.multiselect(\"Select feature columns:\", [col for col in data.columns if col != y_col])\n",
        "        if not X_cols:\n",
        "            st.warning(\"Please select at least one feature column.\")\n",
        "        else:\n",
        "            X = data[X_cols]\n",
        "            y = data[y_col]\n",
        "\n",
        "            task_type = st.radio(\"Confirm Task Type:\", [\"regression\", \"classification\"])\n",
        "            balance = task_type == 'classification' and (y.value_counts(normalize=True).max() <= 0.7)\n",
        "\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            model_list = [\n",
        "                \"Linear Regression\", \"Polynomial Regression\", \"Ridge Regression\", \"Lasso Regression\",\n",
        "                \"ElasticNet Regression\", \"SVM Regression\", \"Decision Tree Regressor\",\n",
        "                \"Random Forest Regressor\", \"Boosting Regressor\", \"KNN Regressor\"\n",
        "            ] if task_type == 'regression' else [\n",
        "                \"Logistic Regression\", \"SVM Classifier\", \"Decision Tree Classifier\",\n",
        "                \"Random Forest Classifier\", \"Boosting Classifier\", \"KNN Classifier\",\n",
        "                \"Naive Bayes Classifier\"\n",
        "            ]\n",
        "\n",
        "            selected_model = st.selectbox(\"Select a model to evaluate:\", model_list)\n",
        "            if st.button(\"Run Selected Model\"):\n",
        "                trained_model, metrics = apply_single_model(X_train, X_test, y_train, y_test, selected_model, task_type, balance)\n",
        "                st.session_state[\"trained_model\"] = trained_model  # Save the trained model to session state\n",
        "                st.session_state[\"X_cols\"] = X_cols  # Save selected feature columns\n",
        "\n",
        "                st.write(f\"Model {selected_model} Performance Metrics:\")\n",
        "                for metric, value in metrics.items():\n",
        "                    st.write(f\"- {metric}: {value:.2f}\")\n",
        "\n",
        "with tabs[2]:  # Future Prediction Tab\n",
        "    st.header(\"Future Prediction\")\n",
        "\n",
        "    if uploaded_file is not None and \"trained_model\" in st.session_state:\n",
        "        st.write(\"Provide data for prediction using the existing features.\")\n",
        "\n",
        "        input_data = {col: st.number_input(f\"Enter value for {col}:\", value=0.0) for col in st.session_state[\"X_cols\"]}\n",
        "        input_df = pd.DataFrame([input_data])\n",
        "        st.write(\"Input Data Preview:\", input_df)\n",
        "\n",
        "        if st.button(\"Generate Prediction\"):\n",
        "            try:\n",
        "                trained_model = st.session_state[\"trained_model\"]\n",
        "                predictions = trained_model.predict(input_df)\n",
        "                st.write(\"Predictions:\", predictions)\n",
        "            except Exception as e:\n",
        "                st.error(f\"An error occurred during prediction: {e}\")\n",
        "    else:\n",
        "        st.warning(\"Please upload a dataset and evaluate a model in the 'Model Evaluation' tab before generating predictions.\")\n"
      ],
      "metadata": {
        "id": "Qa5199y8ETZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42201d8-76c1-4bf9-9507-2dabba5fbea3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace 'YOUR_AUTHTOKEN' with your actual ngrok authtoken\n",
        "ngrok.set_auth_token(\"2rI2XurhgC2fxlYDtteHntWpCJf_5b1kDx2SLmwgq8GukDEyc\")\n",
        "\n",
        "# Run the Streamlit app in the background\n",
        "!streamlit run app1.py &>/dev/null&\n",
        "\n",
        "# Create a public URL using ngrok\n",
        "try:\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"Streamlit app is running at {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Trying to run with localtunnel\")\n",
        "    !streamlit run app1.py &>/content/logs.txt & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "7bdJ-LwmESpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0011ccbc-a22b-4656-f6b2-b30bfa66ff09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is running at NgrokTunnel: \"https://9605-34-82-236-228.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KV2jvw8vM7ph"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}